{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e38e289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "import os\n",
    "import json\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from chromadb.utils import embedding_functions\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# 设置OpenAI API密钥\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "# 加载CSV文件\n",
    "csv_file_path = 'ptt_stock_articles.csv'\n",
    "comments_file_path = 'ptt_stock_comments.csv'\n",
    "\n",
    "df = pd.read_csv(csv_file_path)\n",
    "df_comments = pd.read_csv(comments_file_path)\n",
    "\n",
    "# 将CSV文件转换为JSONL文件\n",
    "jsonl_file_path = 'combined_ptt_stock_documents.jsonl'\n",
    "df.to_json(jsonl_file_path, orient='records', lines=True, force_ascii=False)\n",
    "\n",
    "# 加载JSONL文件\n",
    "loader = JSONLoader(\n",
    "    file_path=jsonl_file_path,\n",
    "    jq_schema='.Content',\n",
    "    json_lines=True,\n",
    "    text_content=True\n",
    ")\n",
    "\n",
    "# 初始化OpenAI Embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# 加载文档\n",
    "documents_load = loader.load()\n",
    "\n",
    "# 初始化Chroma并将文档添加到Chroma\n",
    "chroma_client = chromadb.Client(Settings())\n",
    "\n",
    "# 检查集合是否存在\n",
    "collection_name = 'recommend_collection'\n",
    "collection_list = chroma_client.list_collections()\n",
    "\n",
    "if collection_name in [col.name for col in collection_list]:\n",
    "    print(f\"Collection {collection_name} already exists. Deleting the existing collection.\")\n",
    "    chroma_client.delete_collection(collection_name)\n",
    "\n",
    "# 创建集合\n",
    "collection = chroma_client.create_collection(\n",
    "    name=collection_name,\n",
    "    embedding_function=embedding_functions.OpenAIEmbeddingFunction(\n",
    "        api_key=os.environ['OPENAI_API_KEY'],\n",
    "        model_name=\"text-embedding-ada-002\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# 處理文章並將它們添加到Chroma\n",
    "def process_documents_and_add_to_chroma(documents, collection, batch_size=100, delay=60):\n",
    "    total_docs = len(documents)\n",
    "    for start_idx in range(0, total_docs, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, total_docs)\n",
    "        batch = documents[start_idx:end_idx]\n",
    "        document_ids = [f\"doc_{i}\" for i in range(start_idx, end_idx)]  # 生成文档ID列表\n",
    "        batch_contents = [doc.page_content[:1000] for doc in batch]  # 提取文档内容并限制长度为1000字符\n",
    "        \n",
    "        try:\n",
    "            # 使用 embed_documents 方法來獲取批量文檔的嵌入\n",
    "            batch_embeddings = embeddings.embed_documents(batch_contents)\n",
    "            \n",
    "            # 确保嵌入和ID数量一致\n",
    "            if len(batch_embeddings) != len(batch_contents):\n",
    "                raise ValueError(f\"Number of embeddings ({len(batch_embeddings)}) must match number of documents ({len(batch_contents)})\")\n",
    "            \n",
    "            # 確保 ID 數量與文檔数量一致\n",
    "            if len(document_ids) != len(batch_contents):\n",
    "                raise ValueError(f\"Number of document IDs ({len(document_ids)}) must match number of documents ({len(batch_contents)})\")\n",
    "            \n",
    "            collection.add(documents=batch_contents, embeddings=batch_embeddings, ids=document_ids)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch from index {start_idx} to {end_idx}: {e}\")\n",
    "        \n",
    "        if end_idx < total_docs:\n",
    "            print(f\"Batch {start_idx//batch_size + 1} completed. Waiting for {delay} seconds...\")\n",
    "            time.sleep(delay)\n",
    "\n",
    "# 處理文檔並添加到Chroma\n",
    "process_documents_and_add_to_chroma(documents_load, collection, batch_size=100, delay=60)\n",
    "\n",
    "# 定义新的股票情绪分析prompt模板\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "query = \"請問川普對台股有什麼影響？\"\n",
    "user_question = query\n",
    "\n",
    "template = \"\"\"你是一個股票分析助手，根據使用者提供的問題以及PTT上的文章和留言進行股票情緒分析。\n",
    "\n",
    "PTT上的文章和留言: {background_context}\n",
    "\n",
    "Hard requirements and steps that must be followed:\n",
    "1. 請描述使用者提供的問題。\n",
    "2. 使用提供的PTT資料，分析台股情绪。\n",
    "3. 請列出文章標題和主要內容。\n",
    "4. 請總結每篇文章的情绪（正面、負面、中立）。\n",
    "5. 如果有不一致的評價，請詳細說明。\n",
    "6. 請使用簡明扼要的語言回答。\n",
    "\n",
    "用詞要有禮貌與專業！\"\"\"\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "human_template = \"{user_question}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# 初始化ChatOpenAI\n",
    "chat_model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# 遍歷前幾篇文章的標題和内容，并生成回應\n",
    "try:\n",
    "    responses = []\n",
    "    \n",
    "    for idx, doc in enumerate(documents_load[:3]):  # 只处理前幾篇文章\n",
    "        title = doc.metadata.get('Title', 'No Title')  # 確保文檔中有標題\n",
    "        content = doc.page_content[:1000]  # 限制内容长度为1000字符\n",
    "        \n",
    "        # 生成回應\n",
    "        response = chat_model(chat_prompt.format_messages(background_context=[content], user_question=user_question))\n",
    "        responses.append(f\"Title: {title}\\nContent: {content}\\nResponse: {response.content}\\n\\n\")\n",
    "        print(response)\n",
    "    # 将所有回應保存到文本文件\n",
    "    with open(\"generated_responses_test.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.writelines(responses)\n",
    "        \n",
    "except Exception as e:\n",
    "    response = f\"Error during document processing or response generation: {e}\"\n",
    "    print(response)\n",
    "    with open(\"generated_responses_test.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(response)\n",
    "    \n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
