{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c37e339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest page number: 7549\n",
      "Fetching page 7549\n",
      "Fetching article https://www.ptt.cc/bbs/Stock/M.1721364282.A.ACB.html\n",
      "Fetching article https://www.ptt.cc/bbs/Stock/M.1721364406.A.4FB.html\n",
      "Fetching article https://www.ptt.cc/bbs/Stock/M.1721365467.A.4E9.html\n",
      "Fetching article https://www.ptt.cc/bbs/Stock/M.1721365814.A.7AF.html\n",
      "Fetching article https://www.ptt.cc/bbs/Stock/M.1719872231.A.9BA.html\n",
      "Fetching article https://www.ptt.cc/bbs/Stock/M.1721349002.A.3F4.html\n",
      "Fetching page 7548\n",
      "Fetching article https://www.ptt.cc/bbs/Stock/M.1721356359.A.52C.html\n",
      "Fetching article https://www.ptt.cc/bbs/Stock/M.1721356684.A.291.html\n",
      "Fetching article https://www.ptt.cc/bbs/Stock/M.1721357100.A.14C.html\n",
      "Fetching article https://www.ptt.cc/bbs/Stock/M.1721357144.A.38E.html\n",
      "Fetching article https://www.ptt.cc/bbs/Stock/M.1721357505.A.227.html\n",
      "Fetching article https://www.ptt.cc/bbs/Stock/M.1721358283.A.C23.html\n",
      "Fetching article https://www.ptt.cc/bbs/Stock/M.1721358692.A.953.html\n",
      "Fetching article https://www.ptt.cc/bbs/Stock/M.1721358762.A.6EC.html\n",
      "Fetching article https://www.ptt.cc/bbs/Stock/M.1721358946.A.0D6.html\n",
      "Fetching article https://www.ptt.cc/bbs/Stock/M.1721359614.A.9FC.html\n",
      "Fetching article https://www.ptt.cc/bbs/Stock/M.1721359639.A.27F.html\n",
      "Fetching article https://www.ptt.cc/bbs/Stock/M.1721360094.A.2BE.html\n",
      "Fetching article https://www.ptt.cc/bbs/Stock/M.1721360279.A.67B.html\n",
      "Fetching article https://www.ptt.cc/bbs/Stock/M.1721360596.A.DB1.html\n",
      "Fetching article https://www.ptt.cc/bbs/Stock/M.1721360598.A.2C2.html\n",
      "Fetching article https://www.ptt.cc/bbs/Stock/M.1721360784.A.E7B.html\n",
      "Fetching article https://www.ptt.cc/bbs/Stock/M.1721361110.A.287.html\n",
      "Fetching article https://www.ptt.cc/bbs/Stock/M.1721363208.A.417.html\n",
      "Fetching article https://www.ptt.cc/bbs/Stock/M.1721363301.A.A3D.html\n",
      "Fetching article https://www.ptt.cc/bbs/Stock/M.1721363445.A.44B.html\n",
      "                                                  URL  \\\n",
      "0   https://www.ptt.cc/bbs/Stock/M.1721364282.A.AC...   \n",
      "1   https://www.ptt.cc/bbs/Stock/M.1721364406.A.4F...   \n",
      "2   https://www.ptt.cc/bbs/Stock/M.1721365467.A.4E...   \n",
      "3   https://www.ptt.cc/bbs/Stock/M.1721365814.A.7A...   \n",
      "4   https://www.ptt.cc/bbs/Stock/M.1719872231.A.9B...   \n",
      "5   https://www.ptt.cc/bbs/Stock/M.1721349002.A.3F...   \n",
      "6   https://www.ptt.cc/bbs/Stock/M.1721356359.A.52...   \n",
      "7   https://www.ptt.cc/bbs/Stock/M.1721356684.A.29...   \n",
      "8   https://www.ptt.cc/bbs/Stock/M.1721357100.A.14...   \n",
      "9   https://www.ptt.cc/bbs/Stock/M.1721357144.A.38...   \n",
      "10  https://www.ptt.cc/bbs/Stock/M.1721357505.A.22...   \n",
      "11  https://www.ptt.cc/bbs/Stock/M.1721358283.A.C2...   \n",
      "12  https://www.ptt.cc/bbs/Stock/M.1721358692.A.95...   \n",
      "13  https://www.ptt.cc/bbs/Stock/M.1721358762.A.6E...   \n",
      "14  https://www.ptt.cc/bbs/Stock/M.1721358946.A.0D...   \n",
      "15  https://www.ptt.cc/bbs/Stock/M.1721359614.A.9F...   \n",
      "16  https://www.ptt.cc/bbs/Stock/M.1721359639.A.27...   \n",
      "17  https://www.ptt.cc/bbs/Stock/M.1721360094.A.2B...   \n",
      "18  https://www.ptt.cc/bbs/Stock/M.1721360279.A.67...   \n",
      "19  https://www.ptt.cc/bbs/Stock/M.1721360596.A.DB...   \n",
      "20  https://www.ptt.cc/bbs/Stock/M.1721360598.A.2C...   \n",
      "21  https://www.ptt.cc/bbs/Stock/M.1721360784.A.E7...   \n",
      "22  https://www.ptt.cc/bbs/Stock/M.1721361110.A.28...   \n",
      "23  https://www.ptt.cc/bbs/Stock/M.1721363208.A.41...   \n",
      "24  https://www.ptt.cc/bbs/Stock/M.1721363301.A.A3...   \n",
      "25  https://www.ptt.cc/bbs/Stock/M.1721363445.A.44...   \n",
      "\n",
      "                              Title  \\\n",
      "0       [新聞] 由 4,300 公里海底電纜從澳洲輸電新加坡   \n",
      "1         [新聞] 不受川普保護費說影響 中經院1理由上修台   \n",
      "2            [情報] 2429 銘旺科 申購抽籤日程資訊   \n",
      "3                [心得] 台積電是咒術迴戰裡面的真人   \n",
      "4   [公告] 股票板板規 v4.6 (2024/07/02 修正)   \n",
      "5              [閒聊] 2024/07/19 盤中閒聊   \n",
      "6                     [請益] 請問華航怎麼了？   \n",
      "7                  [標的] 6869 雲豹能源 空   \n",
      "8      Re: [情報] 6405悅城處分台積電普通股股票之公告   \n",
      "9           [新聞] 高盛：人工智慧投資正在泡沫化、短期內   \n",
      "10              [情報] 哇操，台幣貶破32.7了喔？   \n",
      "11              [新聞] 紡纖廠有志一同 大舉投資綠能   \n",
      "12            Re:  [請益]  雲豹到底憑甚麼漲停？   \n",
      "13                   [請益] 請問長榮航怎麼了？   \n",
      "14                   [請益] 955入場的時機點   \n",
      "15                      [標的] 旺矽還是豐藝   \n",
      "16           [請益] 如果川普現在買台積電，算內線交易嗎   \n",
      "17          Re: [標的] 00679B~元大美債20年   \n",
      "18      Re: [新聞] 高盛：人工智慧投資正在泡沫化、短期內   \n",
      "19                [請益] 台灣有那些汽油車概念股?   \n",
      "20               [標的] 3060 銘異 先蹲後跳多   \n",
      "21    [新聞] 卡位AI有優勢 科技股一片殺聲Palantir逆   \n",
      "22         [新聞] 川普口水有多毒？曝光台積電最大弱點 命   \n",
      "23             [標的]1524耿鼎_川普汽車工業概念股   \n",
      "24         Re: [標的] 6820.tw連訊(興櫃) 多   \n",
      "25             Re: [請益]  雲豹到底憑甚麼漲停？   \n",
      "\n",
      "                                              Content  \n",
      "0   原文標題：\\n\\n由 4,300 公里海底電纜從澳洲輸電新加坡，計畫獲重要進展\\n\\n原文連...  \n",
      "1   原文標題：不受川普保護費說影響 中經院1理由上修台灣經濟成長率\\n\\n\\n原文連結：\\n\\n...  \n",
      "2   1. 標題：2429 銘旺科 申購抽籤日程資訊\\n\\n2. 來源：TWSE 公開申購公告-抽...  \n",
      "3   台積電 --> 真人\\n\\n美國 --> 夏油傑\\n\\n美國根本就是牢牢的掌握台積電，\\n等...  \n",
      "4   1. 發文規範與分類總則 2. 股票板板規執法範圍 --------------------...  \n",
      "5   ==============113/07/19台股資訊重點整理，供股民做投資參考======...  \n",
      "6   一堆利好跟利多\\nMSCI空運物流指數也持續在上升\\n華航可以跌倒跌成這樣\\n這波根本完全都...  \n",
      "7   標的：6869 雲豹能源\\n\\n\\n分類：空\\n\\n\\n分析/正文：\\n\\n看到今天這根漲停...  \n",
      "8   中環在幾天前高割離席處分台積電股票，反觀悅城破千才要進來，上次也是套在最高點，之後血虧出場，...  \n",
      "9   高盛：人工智慧投資正在泡沫化、短期內還不會破裂\\n\\n\\n\\nMoneyDJ新聞 2024-...  \n",
      "10  今天早盤台幣貶破32.7了，帶量突破這三年來的高點，現在看這個型態越看越像三角收斂突\\n破 ...  \n",
      "11  原文標題：紡纖廠有志一同 大舉投資綠能\\n\\n\\n原文連結：\\n\\n發布時間：2024.07...  \n",
      "12  一支股票的興衰過程跟市場看法大概是這樣吧\\n\\n有題材，沒營收，初升期\\n：炒作，爛股票，這...  \n",
      "13  一堆利多和營收棒棒der\\nMSCI空運物流指數也持續在上升\\n長榮航可以跌倒跌成這樣\\n這...  \n",
      "14  大家好，小弟最近有個投資上的困惑想請教大家\\n前兩個禮拜949上市時就一直很想買\\n但最近看...  \n",
      "15  剛加入股市不久\\n運氣好有買到旺矽跟豐藝\\n最近台股下跌想要先出一隻\\n不知道各位高手 有沒...  \n",
      "16  基於各種原因\\n最近川普的發言似乎對台積電很不利\\n也導致了台股及台積電下跌\\n那如果這個時...  \n",
      "17  費時 17天 收工\\n\\n元大美債 190張全部賣出\\n\\n\\n\\n對帳單\\n\\n估計是賺1...  \n",
      "18  我不知道現在AI股價是不是泡沫，但AI應用早就超過10年了。\\n\\n應用其實不是大家想像的高...  \n",
      "19  請問台灣有那些汽油車概念股\\n\\n   最好有在美國設廠的...\\n\\n   川普投顧剛剛有...  \n",
      "20  分析/正文：\\n大家好～這是小弟股板首PO\\n銘異我已蹲了一段時間，板上也有大大們發過相關介...  \n",
      "21  原文標題：卡位AI有優勢 科技股一片殺聲Palantir逆勢漲\\n\\n原文連結：\\n\\n發布...  \n",
      "22  原文標題：\\n\\n川普口水有多毒？曝光台積電最大弱點 命運被2國擺弄\\n\\n\\n原文連結：\\...  \n",
      "23  ----------------------------------------------...  \n",
      "24  7/15-7/19五天的時間\\n未實現損益由63%到11X%，希望收盤能穩住\\n\\n\\n連訊...  \n",
      "25  剛出社會的時候股市菜雞一枚\\n\\n傻傻看新聞某家公司營收開得漂亮、或是券商個股券報目標價大於...  \n",
      "                                                    URL push_tag  \\\n",
      "0     https://www.ptt.cc/bbs/Stock/M.1721364282.A.AC...        →   \n",
      "1     https://www.ptt.cc/bbs/Stock/M.1721364282.A.AC...        推   \n",
      "2     https://www.ptt.cc/bbs/Stock/M.1721364282.A.AC...        →   \n",
      "3     https://www.ptt.cc/bbs/Stock/M.1721364282.A.AC...        推   \n",
      "4     https://www.ptt.cc/bbs/Stock/M.1721364282.A.AC...        推   \n",
      "...                                                 ...      ...   \n",
      "2927  https://www.ptt.cc/bbs/Stock/M.1721363445.A.44...        →   \n",
      "2928  https://www.ptt.cc/bbs/Stock/M.1721363445.A.44...        推   \n",
      "2929  https://www.ptt.cc/bbs/Stock/M.1721363445.A.44...        推   \n",
      "2930  https://www.ptt.cc/bbs/Stock/M.1721363445.A.44...        推   \n",
      "2931  https://www.ptt.cc/bbs/Stock/M.1721363445.A.44...        推   \n",
      "\n",
      "       push_userid                push_content    push_time  \n",
      "0           Fezico                    這真的很狂...  07/19 12:45  \n",
      "1          cchh179                    這麼長要消耗多少  07/19 12:46  \n",
      "2             KJK7                   漁船應該很容易勾斷  07/19 12:47  \n",
      "3        oyaji5566               [新聞] 海底「松鼠」出沒  07/19 12:47  \n",
      "4       a069275235                  笑死  厲害了綠能仔  07/19 12:47  \n",
      "...            ...                         ...          ...  \n",
      "2927     v21638245                        都還行啊  07/19 12:42  \n",
      "2928    joshua1226                           党  07/19 12:57  \n",
      "2929      fungling              合一 三期 大陸藥證 幫哭哭  07/19 12:59  \n",
      "2930  sharkman1793                    00713也可以  07/19 13:01  \n",
      "2931         lsgsl  智擎一線藥症明明未來有賺10元實力還是跌爛QQ...  07/19 13:09  \n",
      "\n",
      "[2932 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# 定義要爬取的PTT板塊\n",
    "board = 'Stock'\n",
    "\n",
    "# 建立一個session來維持cookies\n",
    "session = requests.Session()\n",
    "session.cookies.set('over18', '1')  # 設定cookie以通過年齡驗證\n",
    "\n",
    "# 定義抓取最新頁面的函數\n",
    "def get_latest_page_number():\n",
    "    url = f'https://www.ptt.cc/bbs/{board}/index.html'\n",
    "    response = session.get(url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f'Failed to load page {url}')\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    prev_page_link = soup.find('a', string='‹ 上頁')\n",
    "    if prev_page_link:\n",
    "        prev_page_url = prev_page_link['href']\n",
    "        latest_page_num = int(prev_page_url.split('index')[1].split('.html')[0]) + 1\n",
    "        return latest_page_num\n",
    "    else:\n",
    "        raise Exception('Failed to find the latest page number')\n",
    "\n",
    "# 定義抓取多頁的函數\n",
    "def get_article_urls_and_titles(page):\n",
    "    url = f'https://www.ptt.cc/bbs/{board}/index{page}.html'\n",
    "    response = session.get(url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f'Failed to load page {url}')\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    articles = soup.find_all('div', class_='r-ent')\n",
    "    article_info = []\n",
    "    for article in articles:\n",
    "        a_tag = article.find('a')\n",
    "        if a_tag:\n",
    "            title = a_tag.text.strip() if a_tag.text else 'No Title'\n",
    "            article_info.append({'title': title, 'url': 'https://www.ptt.cc' + a_tag['href']})\n",
    "    return article_info\n",
    "\n",
    "# 定義抓取文章內容及留言的函數\n",
    "def get_article_content(url):\n",
    "    response = session.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f'Failed to load article {url}')\n",
    "        return None\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    main_content = soup.find(id='main-content')\n",
    "    \n",
    "    if main_content:\n",
    "        for tag in main_content.find_all(['div', 'span', 'script', 'a']):\n",
    "            tag.decompose()\n",
    "        article_text = main_content.text.strip() if main_content.text else 'No main content found'\n",
    "    else:\n",
    "        article_text = 'No main content found'\n",
    "    \n",
    "    return article_text\n",
    "\n",
    "# 定義抓取留言的函數\n",
    "def get_article_comments(url):\n",
    "    response = session.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f'Failed to load article {url}')\n",
    "        return None\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    pushes = soup.find_all('div', class_='push')\n",
    "    push_tag = []\n",
    "    push_userid = []\n",
    "    push_content = []\n",
    "    push_time = []\n",
    "    \n",
    "    for push in pushes:\n",
    "        push_tag_text = push.find('span', class_='push-tag')\n",
    "        push_userid_text = push.find('span', class_='push-userid')\n",
    "        push_content_text = push.find('span', class_='push-content')\n",
    "        push_time_text = push.find('span', class_='push-ipdatetime')\n",
    "        \n",
    "        push_tag.append(push_tag_text.text.strip() if push_tag_text else 'No Tag')\n",
    "        push_userid.append(push_userid_text.text.strip() if push_userid_text else 'No User ID')\n",
    "        push_content.append(push_content_text.text.strip().lstrip(': ') if push_content_text else 'No Content')\n",
    "        push_time.append(push_time_text.text.strip() if push_time_text else 'No Time')\n",
    "        \n",
    "    comments = pd.DataFrame({\n",
    "        \"URL\": url,\n",
    "        \"push_tag\": push_tag,\n",
    "        \"push_userid\": push_userid,\n",
    "        \"push_content\": push_content,\n",
    "        \"push_time\": push_time\n",
    "    })\n",
    "    return comments\n",
    "\n",
    "# 開始抓取文章\n",
    "all_articles = []\n",
    "all_comments = []\n",
    "\n",
    "# 取得最新的頁數\n",
    "latest_page = get_latest_page_number()\n",
    "print(f'Latest page number: {latest_page}')\n",
    "\n",
    "# 這裡設定要抓取的頁數範圍，可以調整\n",
    "start_page = latest_page\n",
    "end_page = latest_page - 1  # 設定抓取的頁數範圍，例如從最新頁到前一頁\n",
    "\n",
    "for page in range(start_page, end_page - 1, -1):\n",
    "    print(f'Fetching page {page}')\n",
    "    articles_info = get_article_urls_and_titles(page)\n",
    "    for article_info in articles_info:\n",
    "        url = article_info['url']\n",
    "        title = article_info['title']\n",
    "        print(f'Fetching article {url}')\n",
    "        article_text = get_article_content(url)\n",
    "        comments = get_article_comments(url)\n",
    "        if article_text:\n",
    "            all_articles.append({'URL': url, 'Title': title, 'Content': article_text})\n",
    "            if comments is not None:\n",
    "                all_comments.append(comments)\n",
    "        time.sleep(0.5)  # 增加延遲以避免過快訪問\n",
    "\n",
    "# 將結果轉換為DataFrame並顯示或保存\n",
    "df_articles = pd.DataFrame(all_articles)\n",
    "if all_comments:\n",
    "    df_comments = pd.concat(all_comments).reset_index(drop=True)\n",
    "else:\n",
    "    df_comments = pd.DataFrame()\n",
    "\n",
    "print(df_articles)\n",
    "print(df_comments)\n",
    "\n",
    "# 選擇性：將文章內容和留言資料保存到文件\n",
    "df_articles.to_csv('./ptt_stock_articles.csv', index=False, encoding='utf-8-sig')\n",
    "df_comments.to_csv('./ptt_stock_comments.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5b1117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
